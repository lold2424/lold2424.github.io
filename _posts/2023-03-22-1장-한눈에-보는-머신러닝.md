---
layout: single

title: "머신러닝 1장 한눈에 보기"

date: 2023-03-22 13:30:00 +0900
lastmod: 2023-03-22 13:30:00 +0900 # sitemap.xml에서 사용됨

author_profile: true

header:
  overlay_image: https://user-images.githubusercontent.com/91832324/229981423-3a9c5404-403f-4ea8-a721-e941b2f41866.jpg

  overlay_filter: 0.5 # 투명도

categories: 
  - College Python

tags: 
    - Python
    - College

# table of contents
toc: true # 오른쪽 부분에 목차를 자동 생성해준다.
toc_label: "table of content" # toc 이름 설정
toc_icon: "bars" # 아이콘 설정
toc_sticky: true # 마우스 스크롤과 함께 내려갈 것인지 설정
---
# 1. 한눈에 보는 머신러닝

## 1. 머신러닝이란?

**아서 새뮤얼Artuhr Samuel (1959)**

> 컴퓨터 프로그램을 명시적으로 구현하는 대신 컴퓨터 스스로 학습하는 능력를 갖도록 하는 연구 분야
> 

**톰 미첼Tom Mitchell (1977)**

> 과제 T에 대한 프로그램의 성능 P가 경험 E를 통해 향상되면 해당 “프로그램이 경험 E를 통해 학습한다” 라고 말한다.
> 

**Example 1 (스팸 필터)**

스팸spam 메일과 아닌 메일ham의 구분법을 머신러닝으로 학습시킬 수 있으며, 톰 미첼의 머신러닝 정의와 관련해서 다음이 성립한다.

- 작업 T = 새로운 메일의 스팸 여부 판단
- 경험 E = 훈련 데이터
- 성능 P = 스팸 여부 판단의 정확도

**데이터셋 용어**

- **훈련셋**(training set): 머신러닝 프로그램이 훈련(학습)하는 데 사용하는 데이터 집합
- **훈련 사례**(training instance) 혹은 **샘플**(sample): 각각의 훈련 데이터

## 2. 머신러닝 활용

**전통적 프로그래밍**

전통적 프로그래밍 다음 과정으로 진행된다.

1. 문제 연구: 문제 해결 알고리즘 연구
2. 규칙 작성: 알고리즘 규현
3. 평가: 구현된 프로그램 테스트
    - 테스트 통과: 프로그램 론칭
    - 테스트 실패: 오차 분석 후 1단계로 이동

![https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-01.png?raw=true](https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-01.png?raw=true)

**머신러닝 프로그래밍**

스팸으로 지정된 메일에 “광고”, “투^^자”, “무❤료” 등의 표현이 자주 등장하는 경우 새로운 메일에 그런 표현이 사용되면 자동으로 스팸으로 분류하도록 스스로 학습하는 프로그램을 작성한다.

![https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-02.png?raw=true](https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-02.png?raw=true)

**머신러닝 프로그램 학습 과정의 자동화**

머신러닝 프로그램을 학습시키는 과정을 관장하는 **머신러닝 파이프라인** 또는 **MLOps(Machine Learning Operations, 머신러닝 운영)** 의 자동화가 가능하다.

![https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-03.png?raw=true](https://github.com/codingalzi/handson-ml3/blob/master/jupyter-book/imgs/ch01/homl01-03.png?raw=true)

**지도 학습**(supervised learning)은 훈련 데이터에 **레이블**(label) 이라는 답을 표기하여 레이블을 맞추도록 유도하는 학습을 가리킨다. 지도 학습은 기본적으로 **분류**(classification) 또는 **회귀**(regression) 문제에 적용된다.

**비지도 학습(**unsupervised learning)은 군집화, 데이터 시각화, 차원 축소, 예외 탐지, 연관 규칙 학습 등의 프로그램 구현에 적용되며, 프로그램 학습에 레이블이 없는 훈련 데이터를 이용한다.

- **군집화**
    - 쇼핑몰 사이트 방문자를 비슷한 특징을 갖는 사람들의 그룹(남성, 여성, 주말, 주중, 의류, 전자기기 등)으로 묶는 **군집화**clustering 프로그램을 학습시킬 수 있다.
- **데이터 시각화**
    - 많은 특성을 갖는 훈련 데이터를 두 개 또는 세 개의 특성만을 갖는 데이터로 변환한 후 2D 또는 3D로 **시각화가 가능**하다.
    이를 위해 훈련 데이터의 특성을 대표하는 2, 3개의 특성을 추출해야 하며 이를 위해 차원 축소 프로그램을 **비지도 학습이 가능**하다.
- **차원 축소**
    - 훈련 데이터의 **차원을 축소하면 머신러닝 프로그램의 학습이 보다 빠르게 진행**되고 보다 **성능이 좋은 프로그램이 구현**될 수 있다.
- **예외 탐지**
    - 신용카드 거래 중 부정거래 사용을 감지하거나 제조 과정 중 결함있는 제품을 확인하는 일을 예외 탐지라 한다.
    예외 탐지 프로그램은 많은 샘플을 이용해 훈련한 후 새롭게 입력된 샘플의 정상/비정상 여부를 판단해 이상치를 확인한다.
- **연관 규칙 학습**
    - 훈련 데이터 특성 간 흥미로운 관계를 찾는데 비지도 학습이 활용됨
    ex) 마트 판매 기록에 바비큐 소스와 감자를 구매하는 고객이 스테이크도 구매하는 경향이 있음을 파악해 연관된 상품을 가깝게 진열

**준지도 학습**

레이블이 적용된 훈련 데이터의 수가 적고, 레이블이 없는 훈련 데이터가 훨씬 많이 있을 때 **준지도 학습**(semi-supervised learning)을 활용한다. 

준지도 학습은 또한 레이블이 적용된 훈련 데이터의 정보를 전체 훈련 데이터셋으로 전파하는 데에 활용될 수 있다.

예를 들어 구글 포토Google Photos는 가족 사진 몇 장에 사람 이름을 레이블로 지정하면 다른 모든 사진에서 지정된 이름의 사람이 포함된 사진을 찾아준다.

이처럼 실전에 사용되는 많은 머신러닝 알고리즘이 준지도 학습과 지도 학습을 함께 사용한다.

**자기지도 학습**(self-supervised learning)은 레이블이 전혀 없는 샘플로 구성된 데이터셋으로부터 레이블을 모두 갖는 샘플로 구성된 데이터셋을 생성하여 모델 훈련을 진행하는 기법이다.

**강화 학습**

**에이전트**(agent)라고 불리는 학습 시스템이 주어진 상황에서 취한 행동에 따라 보상과 벌점을 받는다. 이를 통해 주어진 상황에서 가장 많은 보상을 받는 **정책**(policy), 즉 최선의 전략(strategy)을 스스로 학습한다. 정책은 특정 상황에서 에이전트가 취해야 하는 최선의 행동을 지정한다.

**실시간 훈련 여부**

**배치 학습**

주어진 훈련셋 전체를 활용해 오프라인에서 훈련하는 것이 **배치 학습(*(batch learning)이다. 한 번 훈련된 시스템은 더 이상의 학습 없이 제품에 적용된다. 배치 학습은 컴퓨팅 자원이 충분한 경우에만 사용할 수 있다.
ex) 스마트폰, 화성 탐사선 등에서는 배치 학습이 어렵다.

**온라인 학습**

**온라인 학습(**online learning)은 하나씩 또는 **미니 배치(**mini-batch)라 불리는 적은 양의 데이터 묶음을 사용해 점진적으로 학습하는 훈련 기법을 가리킨다.

**외부 메모리 학습**

매우 큰 훈련 데이터셋은 메모리에 한꺼번에 불러올 수 없기에 훈련 데이터셋을 미니 배치로 나누어 점진적 학습에 활용할 수 있다. 이를 **외부 메모리 학습**(out-of-core learning)이라 한다.

**예측 모델 사용 여부**

**사례 기반 학습**

새로운 데이터에 대한 예측을 수행하기 위해 기존 샘플과의 **유사도(**similarity)를 측정한 후, 가장 높은 유사도를 갖는 샘플에 대해 사용했던 예측값을 그대로 사용한다.

## 4. 러닝머신 모델 훈련의 어려움

**알고리즘 문제**

- 과대 적합
    - 모델이 훈련 과정에서 훈련셋에 특화되어 일반화 성능이 떨어지는 현상이 **과대 적합**(overfitting)이다.
    - 모델과, 데이터셋 자체, 훈련 방식에 의해 영향을 받는다.
    
    ![Untitled](https://user-images.githubusercontent.com/91832324/229984977-9beb21d0-f8f1-4f9c-902a-4d9102592dc0.png)
    
- 과소 적합
    - 모델이 너무 단순해서 훈련셋을 제대로 대변하지 못하는 경우를 **과소 적합**(underfitting)이라 한다.
    - 보통 잘못된 모델을 선택했을 경우 발생한다.
    
    ![Untitled 1](https://user-images.githubusercontent.com/91832324/229984978-eabd5508-539f-4891-ba5d-693b55e278f3.png)


**테스트와 검증**

훈련된 모델의 성능을 평가하기 위해 **테스트셋**(test set)을 활용한다. 테스트셋은 전체 데이터셋의 일부로 구성된다. 보통 20% 정도를 테스트셋으로 남겨 둔 후 나머지 80% 만을 이용하여 모델을 훈련시킨다. 즉, 모델 훈련 과정동안 테스트셋에 포함된 데이터를 모델은 전혀 보지 못한다.

물론 데이터셋이 매우 크면 테스트셋 비율을 낮출 수 있다. 예를 들어 천만 개의 데이터가 있으면 그중 1% 정도인 10만 개를 테스트용으로 사용해도 된다. 즉, 테스트셋은 훈련셋보다 상대적으로 많이 작아도 된다. 핵심은 테스트셋이 훈련에 전혀 사용되지 않아야 한다는 점이다.

**일반화 오차 vs 훈련 오차**

테스트를 통해 훈련된 모델의 일반화 성능을 확인한다. 일반화 성능은 훈련 과정 중에 접하지 않는 새로운 데이터에 대해 모델의 예측이 얼마나 틀리는가를 계산한 **일반화 오차**(generalization error)로 측정된다. 반면에 **훈련 오차**(training error)는 훈련 과정에 사용된 데이터에 대한 모델의 예측이 틀린 정도를 가리킨다.

**교차 검증**

일반화 성능이 높은 모델을 훈련시키기 위해 많이 사용되는 방식 중 하나가 **교차 검증**(cross validation)이다. 교차 검증은 훈련 데이터셋의 일부인 **검증 셋**(validation set)을 이용하여 훈련 과정중에 훈련 중인 모델의 일반화 성능을 검증하는 기법이며, 이를 통해 일반화 성능이 높은 모델을 훈련시키도록 유도한다.