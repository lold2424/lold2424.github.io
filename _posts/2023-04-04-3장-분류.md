---
layout: single

title: "머신러닝 3장 분류"

date: 2023-04-04 16:30:00 +0900
lastmod: 2023-04-04 16:30:00 +0900 # sitemap.xml에서 사용됨

author_profile: true

header:
  overlay_image: https://images.unsplash.com/photo-1501785888041-af3ef285b470?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1350&q=80
  overlay_filter: 0.5 # 투명도

categories: 
  - College Python

tags: 
    - Python
    - College

# table of contents
toc: true # 오른쪽 부분에 목차를 자동 생성해준다.
toc_label: "table of content" # toc 이름 설정
toc_icon: "bars" # 아이콘 설정
toc_sticky: true # 마우스 스크롤과 함께 내려갈 것인지 설정
---
# 3장 분류

## 1. MNIST

**MNIST 데이터셋**

- 미국 고등학생과 인구조사국 직원들이 손으로 쓴 70,000개의 숫자 이미지로 구성된 데이터셋
- 사용된 0 ~ 9까지 숫자는 모두 28x28 크기의 픽셀로 구성된 이미지 데이터
- 2차원 어레이가 아닌 길이가 784(28x28)인 1차원 어레이로 제공
- 레이블: 70,000개 이미지

**문제 정의**

- 지도학습: 각 이미지가 담고 있는 숫자가 레이블로 지정됨.
- 분류 모델: 이미지 데이터를 분석하여 0부터 9까지의 숫자로 분류
- 이미지 그림을 총 10개의 클래스로 분류하는 **다중 클래스 분류 (**multiclass classification).
- 배치 또는 온라인 학습: 둘 다 가능

**훈련셋과 데이터셋**

- MNIST 데이터셋 이미 6:1 분류되어 있음
- 훈련 셋: 앞 60,000개 이미지
- 테스트 셋: 나머지 10,000개 이미지
## 2. 이진 분류기 훈련

**예제: 숫자 5 감지기**

- 이미지 샘플이 숫자 5를 표현하는지 여부를 판단하는 이진 분류기
- 모든 레이블을 0 OR 1로 수정해야 함
	- 0: 숫자 5 이외의 수를 가리키는 이미지 레이블
	- 1: 숫자 5를 가리키는 이미지 레이블

**SGD 분류기 활용**

- 확률적 경사 하강법(stochastic gradient descent) 분류기
- 한 번에 하나씩 훈련 샘플 처리 후 파라미터 조정
- 매우 큰 데이터셋 처리에 효율적, 온라인 학습에도 적합
- 훈련: `fit()` 메서드 호출
## 3. 분류기 성능 측정

**측정 기준**

- 정확도
- 정밀도/재현율
- ROC 곡선의 AUC

**교차 검증 활용 정확도 측정**

- 숫자 5를 표현하는 이미지를 정확히 예측한 비율.
- `cross_val_score`모델의 `scoring="accuracy"`키워드 인자 지정

**95%의 정확도를 갖는 분류기 이해**

- 교차 검증 결과: 95% 이상의 정확도
- but, 무조건 ‘5 아님’이라 찍는 분류기도 90%의 정확도를 보임
- 훈련 셋의 샘플이 **불균형으로 구성된다면, 정확도를 분류기의 성능 측정 기준으로 사용하는건 피해야 함.**

**오차 행렬, 정밀도, 재현율**

- 오차 행렬을 이용해 분류기의 또다른 성능 측정 기준인 정밀도와 재현율 설명

**오차행렬**

- 오차행렬: 클래스별 예측 결과의 참/거짓을 정리한 행렬
- 숫자-5 감지기에 대한 오차 행렬
	
	array([[53892,   687],
				[ 1891,  3530]])
	

**오차 행렬 해석**

- 이진 분류기의 오차행렬 내용
	- TN(참 음성): 음성을 음성으로 잘 예측
	- FP(거짓 양성): 음성을 양성으로 잘못 예측
	- FN(거짓 음성): 양성을 음성으로 잘못 예측
	- TP(참 양성): 양성을 양성으로 잘 예측
- 아래 그림에 대한 오차 행렬
	
	array([[5, 1],
				[2, 3]])
	
	![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c091653a-94d6-4d9f-9161-17d80d1d474a/Untitled.png)
	

**정밀도(precision)**

- 양성 예측의 정확도
- 예제: 숫자 5라고 예측된 값 중 진짜 5인 숫자들의 비율
	- 정밀도 = TP / (TP + FP) = 3530 / (3530 + 687) = 0.837

**재현율(recall)**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/be2b0787-261a-44c8-b47b-f65e9725b4e3/Untitled.png)

- 양성 샘플에 대한 정확도, 즉, 분류기가 정확히 감지한 양성 샘플의 비율
- 재현율을 **민감도** OR **참 양성 비율**로 부름
	- 재현율 = TP / (TP + EN) = 3530 / (3530 + 1891) = 0.651

**정밀도 VS 재현율**

- 목정에 따라 정밀도와 재현율의 중요도가 다름
- 정밀도(Precision)
	- 양성으로 예측한 샘플 중 실제 양성인 샘플의 비율을 나타냄
	- 즉, 양성으로 예측한 것 중에 얼마나 실제로 양성인 것을 잘 예측했는지를 나타냅니다.
- 재현율(Recall)
	- 양성인 샘플 중 양성으로 예측한 샘플의 비율을 나타냅니다.
	- 즉, 실제 양성인 것 중에 얼마나 많은 것을 양성으로 예측했는지를 나타냅니다.

**정밀도/재현율 트레이드오프**

- 정밀도와 재현율은 상호 반비례 관계
- 정밀도와 재현율 사이 적절한 비율을 유지하는 분류기를 찾아야함.
- 적절한 결정 임곗값을 지정

**결정 함수와 결정 임곗값**

- 결정 함수: 각 훈련 샘플에 대한 점수를 계산하는 함수
- 결정 임계값: 결정 함수가 양성 클래스 OR 음성 클래스로 분류하는데 사용되는 기분값
- 결정 임곗값이 클 수록 정밀도는 증가하나 재현율은 감소함

**임곗값, 재현율, 정밀도**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/055a2574-ceea-4bde-b783-7de7268f904e/Untitled.png)

- **임계값(threshold)가 낮을수록 재현율은 높아지지만, 정밀도는 낮아집니다.** 반대로, **임계값이 높을수록 정밀도는 높아지지만, 재현율은 낮아집니다.**
- 이 그림에서 녹색 선과 파란색 점선이 교차하는 지점은 재현율과 정밀도가 균형을 이루는 지점으로, 이 지점에서 분류기는 최적의 성능을 보입니다. 이 지점에서 임계값이 0.5인 것으로 나타나 있는데, 이는 일반적으로 이진 분류에서 사용되는 기본값입니다. 그러나 문제에 따라 다른 값을 선택해야 할 수도 있습니다.

**재현율 VS 정밀도**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/946529c0-6477-4eb4-8d9b-d60600172c18/Untitled.png)

**ROC 곡선의 AUC**

- 수신기 조작 특성(receiver operating characteristic, ROC) 곡선을 활용해 이진 분류기의 성능 측정 가능
- ROC 곡선: 거짓 양성 비율(FPR)에 대한 참 양성 비율(TPR)의 관계를 나타내는 곡선
- 참 양성 비율: 재현율
- 거짓 양성 비율: 원래 음성인 샘플 중에서 양성이라고 잘못 분류된 샘플들의 비율.
예를 들어, 5가 아닌 숫자중에서 5로 잘못 예측된 숫자의 비율
	- FPR = FP / (FP + TN)

**참 양성 비율(TPR) VS 거짓 양성 비율(FPR)**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fcfefc00-8fd1-4064-bec0-3d068299d388/Untitled.png)

- 파란색 곡선이 랜덤한 곡선보다 위쪽에 위치하면서 좌상단 모서리에 가까이 위치해 있는 것은 해당 분류기의 성능이 상대적으로 우수하다는 것을 의미

**AUC와 분류기 성능**

- 재현율(TPR)과 거짓 양성 비율(FPR) 사이에 서로 상쇄하는 기능이 있다는 것을 확인 가능
- 즉, 재현율(TPR)을 높이고자 하면 거짓 양성 비율(FPR)도 함께 증가
- 좋은 분류기는 재현율은 높으면서 거짓 야엉 비율은 최대한 낮게 유지해야함
- ROC 곡선이 y축에 최대한 근접하는 결과가 나오도록 해야함.
- AUC(ROC 곡선 아래의 면적)가 1에 가까울 수록 성능이 좋은 분류기로 평가

**SGD와 랜덤 포레스트의 AUC 비교**

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9c893689-2185-452f-8729-ebad170143cb/Untitled.png)

## 4. 다중 클래스 분류

**다중 클래스 분류**

- 세 개 이상의 클래스로 샘풀을 분류하는 예측기
- 다항 분류기(multinomial classifier)라고 부름
- 예를 들어, 손글씨 숫자 분류의 경우 0 ~ 9까지 10개의 클래스로 분류해야 함

**다중 클래스 분류 지원 분류기**

- SGD 분류기
- 랜덤 포레스트 분류기
- 나이브 베이즈(Naive Bayes) 분류기

**이진 분류먄 지원하는 분류기**

- 로지스틱 회귀
- 서포트 벡터 머신(SVM)

**이진 분류기 활용 클래스 분류**

- 이진 분류기를 활용해 다중 클래스 분류 가능
- 일대다(OvR 또는 OvA)
- 일대일(OvO)

**손글씨 분류: 일대다 방식 활용법**

- 숫자-5 예측기와 동일한 방식으로 모든 숫자에 대해 이진 분류기 실행
- 각 샘플에 대해 총 10개의 이진 분류기 훈련
- 각 샘플에 대해 가장 높은 결정 점수를 주는 이진 분류기에 해당하는 클래스 선택

**손글씨 분류: 일대일 방식**

- 각 샘플에 대해 가능한 모든 조합의 일대일 대결 분류기 훈련 진행 후 가장 승률이 높은 숫자 선택
- MNIST의 경우, 0과 1 구별, 0과 2 구별, …, 1과 2 구별, 1과 3 구별, …, 8과 9 구별 등 총 45개의 분류기 활용.
- 각각의 분류기는 해당되는 샘플만 훈련에 사용.
예를 들어, 0과 1을 구별하는 분류기는 0과 1에 해당하는 샘플만으로 훈련.

## 5. 오류 분석

**오차 행렬 활용**

- 왼쪽 이미지: 손글씨 클래스 분류 모델의 오차 행렬을 이미지로 표현 가능
	- 대체로 잘 분류됨: 대각선이 밝음
	- 5행은 좀 어두움 → 숫자 5의 분류 정확도가 상대적으로 낮음
- 우측 이미지: 행별로 100분율 계산

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8cc6ea02-de20-4614-a3b3-98354657fb24/Untitled.png)

**오차율 이미지**

- 좌측 이미지: 8번 열이 밝음 → 많은 숫자가 8로 오인됨.
- 우측 이미지:
	- 7로 오인된 숫자중에 9의 비중이 56%로 가장 높음.
	- 5로 오인된 숫자중에 3의 비중이 34%로 가장 높음.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/055da61d-0c10-4760-b43c-6cd0cada5ce1/Untitled.png)

**3과 5 대상 오차행렬**

- 음성: 3으로 판정
- 양성: 5로 판정

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/de743fcc-62a1-4c0c-9437-e97ce4aef77a/Untitled.png)

**데이터 증식**

- 사용한 SGD 분류 모델은 선형 회귀를 사용하는데 성능이 좋지 않음.
- 좋은 성능의 모델을 사용할 수 있지만 기본적으로 보다 많은 훈련 이미지가 필요하다.
- 새로운 이미지를 구할 수 있으면 좋겠지만 어렵다.
- 기존의 이미지를 조금씩 회전하거나, 뒤집거나, 이동하는 방식 등으로 보다 많은 이미지를 훈련셋에 포함시킬 수 있다.
- 이런 방식을 **데이터 증식(**data augmentation)이라 부른다.
## 6. 다중 레이블 분류와 다중 출력 분류

**다중 레이블 분류**

- 샘플마다 여러 종류의 레이블에 대한 값 예측
- 예측
	- 손글씨 사진이 기리키는 숫자가 7 이상인지 여부와 홀수 여부도 함께 예측
	- 숫자 5를 가리키는 이미지의 예측값: `[False, True]`

**다중 출력 분류**

- 다중 출력 다중 클래스 분류라고 불림
- 다중 레이블 분류를 일반화한 것: 각각의 레이블에 대해 다중 클래스 분류 진행 가능
	- 이전 예제는 각각의 레이블에 대해 이진 분류 진행