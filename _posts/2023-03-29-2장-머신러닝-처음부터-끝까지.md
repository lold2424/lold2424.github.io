---
layout: single

title: "머신러닝 2장 처음부터 끝까지"

date: 2023-03-29 13:30:00 +0900
lastmod: 2023-03-29 13:30:00 +0900 # sitemap.xml에서 사용됨

author_profile: true

header:
  overlay_image: https://user-images.githubusercontent.com/91832324/229981423-3a9c5404-403f-4ea8-a721-e941b2f41866.jpg

  overlay_filter: 0.5 # 투명도

categories: 
  - College Python

tags: 
    - Python
    - College

# table of contents
toc: true # 오른쪽 부분에 목차를 자동 생성해준다.
toc_label: "table of content" # toc 이름 설정
toc_icon: "bars" # 아이콘 설정
toc_sticky: true # 마우스 스크롤과 함께 내려갈 것인지 설정
---
# 2. 머신러닝 프로젝트 처음부터 끝까지

## 1. 실전 데이터 활용

데이터를 모아놓은 저장소중 유명한 사이트는 아래와 같다.

- [OpenML](https://www.openml.org/)
- [Kaggle](http://www.kaggle.com/datasets)
- [Papers With Code](https://paperswithcode.com/)
- [UC Irvine](http://archive.ics.uci.edu/ml)
- [아마존 AWS](https://registry.opendata.aws/)
- [TensorFlow](https://www.tensorflow.org/datasets)

## 2. 큰 그림 그리기

**데이터 정보 확인**

1990년도에 시행된 미국 캘리포니아 주의 20,640개 구역별 인구조사 데이터는 경도, 위도, 중간 주택 연도, 방의 총 개수, 침실 총 개수, 인구, 가구 수, 중간 소득, 중간 주택 가격, 해안 근접도 등 총 10개의 특성을 포함한다.

**훈련 모델 확인**

- **지도 학습:** 구역별 ‘중간 주택 가격’을 타깃target으로 지정한다.
→ **타깃: 구역별 중간 주택 가격**
- **회귀: 중간 주택 가격을 예측**한다. 보다 세분화하면 다중 회귀이자 단변량 회귀 모델이다.
    - **다중 회귀multiple regression:** 구역별로 여러 특성을 주택 가격 예측에 사용한다.
    - **단변량 회귀univariate regression:** 구역별로 한 종류의 값만 예측한다.
- **배치 학습:** 빠르게 변하는 데이터에 적응할 필요가 없으며, 데이터셋의 크기도 충분히 작다.

**훈련 모델 성능 측정 지표**

선형 **회귀 모델**의 경우 일반적으로 아래 두 기준 중 하나를 사용한다.

- 평균 제곱근 오차**(RMSE)**
    
    평균 제곱근 오차(RMSE)는 **예측값과 타깃 사이의 오차의 제곱의 평균값**이다.
    
    **유클리디안 노름** 또는 **ℓ2 노름**으로 불린다.
    노름(norm)은 거리 측정 기준을 나타냄
    
    오차가 작을수록 좋긴 하나 너무 작을경우에도 좋지않다.
    
    ![Untitled](https://user-images.githubusercontent.com/91832324/229984197-d2dcde2f-aa9d-4803-9c83-e97c367fadcf.png)

    
    ![Untitled 1](https://user-images.githubusercontent.com/91832324/229984230-b6be8a61-8452-489a-82ad-21d67976a4e0.png)

- 평균 절대 오차**(MAE)**
    
    **평균 절대 오차**(MAE)는 **맨해튼 노름** 또는 **ℓ1 노름**으로도 불리며 예측값과 타깃 사이의 오차의 평균값이다.
    
    예측을 너무 못하면 MAE가 더 좋다.
    
    훈련셋에 이상치가 많이 포함된 경우 주로 사용되지만, 그렇지 않다면 **일반적으로 RMSE가 선호**된다.
    
## 3. 데이터 훑어보기

- 여기서는 `housing`변수에 주택 가격 데이터를 담고있다.


## 4. 데이터 탐색과 시각화

**지리적 데이터 시각화**

![Untitled 2](https://user-images.githubusercontent.com/91832324/229984239-05dcd3ec-7253-47a7-a899-bf8f10494c8e.png)    

위 그림처럼 주어진 데이터를 산포도로 시각화를 할 수 있다.

`alpha`인자를 사용해서 투명도를 조절할 수 있다.

![Untitled 3](https://user-images.githubusercontent.com/91832324/229984240-2bf81e3e-727e-4150-8710-3a2d01240372.png)

산포도를 지도와 합쳐서 산포도로 시각화가 가능하다.

**상관관계 조사**

중간 주택 가격 특성과 다른 특성 사이의 선형 **상관관계를 나타내는 상관계수**는 다음과 같다.

![Untitled 4](https://user-images.githubusercontent.com/91832324/229984242-d00e81b4-bbc7-497d-a1c7-ecd8fe17932b.png)


- 상관관계의 특징
    - 상관계수는 -1에서 1 사이의 값으로 표현된다.

![Untitled 5](https://user-images.githubusercontent.com/91832324/229984244-9548a3aa-9eac-40ed-8f1e-ad48ed61687b.png)

산점도를 그리면 위와 같이 나오는데 선이 있는게 보인다.

그 이유는 아래와 같다.

- 50만 달러에서 보이는 수평선은 가격을 제한한 결과로 보여진다.
(시각화하는 과정에서 보이는 가격을 50만으로 제한)
- 45만, 35만, 28만, 그 아래 정도에서도 수평선이 존재하는데 이유는 알려지지 않았다.
- 이처럼 이상한 성질을 모델이 형태를 학습하지 못하도록 해당 구역을 제거하는 것이 일반적으로 좋다. 하지만 여기서는 그대로 두고 사용한다.
## 5. 데이터 준비

- **데이터 준비 자동화**
    - 모든 전처리 과정을 **파이프라인**을 이용해 자동화 가능
- **입력 데이터셋과 타깃 데이터셋**
    - 계층 샘플링으로 얻어진 훈련셋 `**strat_train_set**` 을 다시 입력 데이터셋 과 타깃 데이터셋으로 구분한다.
    - 입력 데이터셋: 중간 주택 가격 특성이 제거된 훈련셋
    
    > housing = strat_train_set.drop("median_house_value", axis=1)
    > 
    - 타깃 데이터셋: 중간 주택 가격 특성으로만 구성된 훈련셋
    
    > housing_labels = strat_train_set["median_house_value"].copy()
    > 
    - 테스트 세트는 훈련이 완성된 후에 성능 측정 용도로만 사용.
    테스트 셋은 건드리지 않는다고 생각하면 됨

**데이터 정제와 전처리**

- **데이터 정제**: 결측치 처리, 이상치 및 노이즈 데이터 제거
    - 구역별 방 총 개수( total_rooms ) 특성에 결측치 포함됨
- **데이터 전처리**
    - **범주형** 특성 전처리 과정
    머신러닝은 숫자로 바꿔야 처리가 가능하다.
        - 원-핫-인코딩
    - **수치형** 특성에 대한 전처리
        - 특성 크기 조정
        - 특성 조합
- **파이프라인**
    - 여러 사이킷런 API를 묶어 순차적으로 처리하는 사이킷런 API
    - 여러 과정을 한 번에 엮어서 수행하도록 하는 도구
- **사이킷런 API 활용**
    - 사이킷런Scikit-Learn의 API를 간단하게 합성 가능
    - 사이킷런 API의 세 가지 유형
        1. 추정기
            - `**fit()` 메서드를 제공**하는 클래스의 객체
            - 주어진 데이터로부터 필요한 정보인 파라미터parameter 계산
            - 계산된 파라미터를 객체 내부의 속성attribute으로 저장
            - 반환값: 계산된 파라미터를 속성으로 갖는 객체
        2. 변환기
            - `fit()` 가 계산한 값을 이용하여 **데이터셋을 변환하는 `transform()` 메서드** 지원.
        3. 예측기
            - `fit()` 가 계산한 값을 이용하여 **예측에 활용하는 `predict()` 메서드** 지원.
            - `predict()` 메서드가 예측한 값의 **성능을 측정하는 `score()` 메서드** 지원.
            - 일부 예측기는 예측값의 신뢰도를 평가하는 기능도 제공
        - 변환기 예측기는 추정기가 될 수 있지만 추정기는 변환기와 예측기가 아닐 수 있음

**데이터 정제**

- **결측치 처리, 이상치 및 노이즈 데이터 제거**

`total_bedrooms` 특성에 207개 구역에 대한 값이 `NaN` (Not a Number)로 채워져 있음, 즉, 일부 구역에 대한 정보가 누락됨.

![Untitled 6](https://user-images.githubusercontent.com/91832324/229984371-2886d29a-3942-4fa8-8d3d-aac1612e6754.png)

- **누락치 처리 방법**
    1. 해당 샘플(구역) 제거
    2. 해당 특성 삭제
    3. 평균값, 중앙값, 0, 주변에 위치한 값 등 특정 값으로 채우기. 여기서는 중앙값 사용.
- **SimpleImputer 변환기**
    - 3번 방법을 지원하는 **사이킷런 변환기**
    - 중앙값 등 통계 요소를 활용하여 누락치를 지정된 값으로 채움

**범주형 특성 다루기(원-핫 인코딩)**

- 범주형 특성을 why 사용하는가? - **단순 수치화의 문제점**
    - 뷰가 좋은 곳은 가격이 비쌈
    - 머신러닝은 숫자가 높다면 중요하다고 인지하기 때문에 잘못된 학습이 될 수 있음
- **원-핫 인코딩(**one-hot encoding)
    - 수치화된 범주들 사이의 크기 비교를 피하기 위해 더미(dummy) 특성을 추가하여 활용
    - 해안 근접도 특성 대신에 다섯 개의 범주 전부를 새로운 특성으로 추가한 후 각각의 특성값을 아래처럼 지정
        - 해당 카테고리의 특성값: 1
        - 나머지 카테고리의 특성값: 0
    - 예제: INLAND 특성을 갖는 구역은 길이가 5인 다음 어레이로 특성으로 대체됨.
        
        > [0, 1, 0, 0, 0]
        > 
    - 더미 특성에 대해 한 곳은 1, 나머지는 0의 값을 취하도록 모델의 훈련이 유도됨
    
    ```python
    from sklearn.preprocessing import OneHotEncoder
    
    cat_encoder = OneHotEncoder()
    housing_cat_1hot = cat_encoder.fit_transform(housing_cat)
    # fit은 범주가 몇개인지 확인
    ```
    

**수치형 특성 전처리: 크기 조정**

머신러닝 알고리즘은 입력 데이터셋의 특성값들의 **크기**scale가 다르면 제대로 작동하지 않는다. 따라서 모든 특성의 크기를 통일하는 **크기 조정**scaling이 요구된다.

크기 조정은 보통 아래 두 가지 방식을 사용한다.

- **min-max 크기 조정(정규화)**
    - **정규화(**normalization)라고도 불리는 min-max 크기 조정은 아래 식을 이용하여 모든 특성값을 0에서 1 사이의 값으로 변환한다. 단, ***max***와 ***min**은* 각각 특성값들의 최댓값과 최솟값을 가리킨다.
        
        ![Untitled 7](https://user-images.githubusercontent.com/91832324/229984377-e8061a89-2456-41d5-bcaf-aa5926548a60.png) 
    - 변환 결과: 0에서 1 사이
    - 이상치가 있는경우 문제가 발생함
    ex) max나 min값이 너무 작거나 큰 경우 대부분의 표본들이 한쪽에 치우치게 됨
    - 사이킷런의 MinMaxScaler 변환기 활용 가능
- **표준화**
    - 특성값을 다음과 같이 변환. 단, 는 특성값들의 평균값mean, 는 특성값들의 표준편차
        
        ![Untitled 8](https://user-images.githubusercontent.com/91832324/229984380-dcde547d-6858-40ad-be8f-4601fb481fd4.png)

    - 변환된 데이터들이 표준정규분포에 가까워 지며, 이상치에 상대적으로 영향을 덜 받음.
    - 사이킷런의 StandardScaler 변환기 활용 가능
- **사용자 정의 변환기**
    
    **사용자 정의 변환기**
    
    **`FunctionTransformer`변환기**
    
    - `fit()` 메서드를 먼저 사용하지 않고 `transform()` 메서드를 바로 적용해도 되는 변
    환기를 선언할 때 사용
    
    **로그 함수 적용 변환기**
    
    - 데이터셋이 두터운 꼬리 분포를 따르는 경우, 즉 히스토그램이 지나치게 한쪽으로 편향된 경우
    - 크기 조정을 적용하기 전에 먼저 로그 함수를 적용 추천
        
        > FunctionTransformer(np. log, inverse_func= np. exp)
        > 
    
    ![Untitled 9](https://user-images.githubusercontent.com/91832324/229984383-a1de8643-096a-4c72-a901-650d035ecd37.png)


**비율 계산 변환기**

- 두 개의 특성 사이의 비율을 계산하여 새로운 특성을 생성하는 변환기
    
    > FunctionTransformer(l a m b d a X: X[:, [0]] / X[:, [1]])
    > 
- 비율 계산 변환기를 이용하여 아래 특성을 새로 생성 가능
    - 가구당 방 개수(rooms for household)
    - 방 하나당 침실 개수(bedrooms for room)
    - 가구당 인원(population per household)

**군집 변환기**

- 캘리포니아 주 2만 여개의 구역을 서로 가깝게 위치한 구역들로 묶어 총 10개의 군집으로 구분하는 변환기 클래스 선언
- 사이킷런의 다른 변환기와 호환이 되도록 하기 위해 fit() , transform(), get_feature_names_out() 선언 필요
- 모든 구역을 **10개의 군집으로 분류**
- 🗙는 각 군집의 중심 구역

![Untitled 10](https://user-images.githubusercontent.com/91832324/229984386-5ba1eb4a-a45e-4ede-ae80-f79018fff01f.png)

`ColumnTransformer`을 사용하면 여러 변환기를 병렬로 독립적으로 실행이 가능하다.